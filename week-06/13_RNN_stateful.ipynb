{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise on Stateful Recurrent Neural Network: \n",
    "\n",
    "**In this exercise we want to use an improved RNN model for predicting if a ice cream store has ice on stock today. We only can use the past weather to make our predictions and hope that the ice stock today depends on the weather in the past couple of days.** \n",
    "\n",
    "**The weather is described by 3 states: 0=sunny, 1=cloudy and 2=rainy. People only buy ice when its sunny and the ice cream stand has an unknow stock of ice and reorders sometimes (unknown policy but we hope it depends on the weather).\n",
    "Unfortunately, we are quite busy with working so we can only remember the weather of the last 2 days - for that reason our lookback is only 2 days.**\n",
    "\n",
    "**To improve the simple RNN model we will use a stateful RNN model.  This means we will pass the learned hidden state into the next mini-batch connecting to the continuation of the sequence (not reset it to zero!). (For prediction with this stateful RNN we need to work on the test data with the same minibatch size as we have used for training). To work with a stateful RNN model we need to prepare our mini-batches in a special way - the first example of the fist batch has to be connected to the first example of the second batch and so on (see lecture slides).**  \n",
    "**The idea  of passing the current hidden state into the next mini-batch is, that we can learn something from the past of the sequence that is further behind than only two steps (the past is summerized in the current hidden state).**\n",
    "\n",
    "\n",
    "**a) Look at RNN model definition, the data preparation, and the model training, what is different compared to the simple RNN?**       \n",
    "\n",
    "**b) Take the trained model and predict the first two examples of the test set. What are the probabilities for ice/no-ice for this two examples?**   \n",
    "\n",
    "**c) Complete the code to do the prediction by \"hand/numpy\" using the extracted weight matrices. (We use model.get_weights() to get the learned weights.) Which state-values do we need to give the in-coming hidden state have for example 1 and for example 2 of the test data? Do we get the same probability vectors as we got it with model.predict?**\n",
    "\n",
    "**d) Assess the performance of the stateful RNN model on the test data set. How does the achieved accuracy compare to the accuracy you have achieved with a simple RNN model?**\n",
    "\n",
    "**e) Explain why the stateful RNN model does outperform the simple RNN model in our example. (Hint: remember the data generating process) How could you improve the performance of the simple RNN model? Play around with the code to check your ideas.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__, sys.version_info\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    Xs = np.array(np.random.choice(3, size=(size,))) #Random Weather\n",
    "    Y = []\n",
    "    ice = 2 # stock of icecream at start\n",
    "    for t,x in enumerate(Xs):\n",
    "        # (t-3) >= 0 the first ice cream could be delivered on day 3\n",
    "        # Xs[t - 3] claudy three days before today => we ordered ice cream\n",
    "        # ice < 2 not full\n",
    "        if (t - 3) >= 0 and Xs[t - 3] == 1 and ice < 2: \n",
    "            ice += 1\n",
    "        if x == 0: # It is sunny we therefore sell ice, if we have\n",
    "            if ice > 0: # We have ice cream\n",
    "                ice -= 1\n",
    "        if ice > 0: #We are not out of stock\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "    return Xs, np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating the data and split it to a train valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = gen_data(40000) \n",
    "\n",
    "lookback=2\n",
    "\n",
    "X_tr = X[0:20000]\n",
    "Y_tr = Y[0:20000]\n",
    "idx=np.arange(0, len(X_tr),lookback)\n",
    "X_train=np.zeros((len(idx),lookback))\n",
    "Y_train=np.zeros((len(idx),1))\n",
    "for i in range(0,len(idx)-1):\n",
    "    X_train[i]=X_tr[idx[i]:idx[i+1]]\n",
    "    Y_train[i]=Y_tr[idx[i]+lookback]\n",
    "\n",
    "X_va = X[20000:30000]\n",
    "Y_va = Y[20000:30000]\n",
    "idx=np.arange(0, len(X_va),lookback)\n",
    "X_valid=np.zeros((len(idx),lookback))\n",
    "Y_valid=np.zeros((len(idx),1))\n",
    "for i in range(0,len(idx)-1):\n",
    "    X_valid[i]=X_va[idx[i]:idx[i+1]]\n",
    "    Y_valid[i]=Y_va[idx[i]+lookback]\n",
    "\n",
    "X_te = X[30000:40000]\n",
    "Y_te = Y[30000:40000]\n",
    "idx=np.arange(0, len(X_te),lookback)\n",
    "X_test=np.zeros((len(idx),lookback))\n",
    "Y_test=np.zeros((len(idx),1))\n",
    "for i in range(0,len(idx)-1):\n",
    "    X_test[i]=X_te[idx[i]:idx[i+1]]\n",
    "    Y_test[i]=Y_te[idx[i]+lookback]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting to one hot encoding for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "X_train=to_categorical(X_train,3)\n",
    "Y_train=to_categorical(Y_train,2)\n",
    "\n",
    "X_valid=to_categorical(X_valid,3)\n",
    "Y_valid=to_categorical(Y_valid,2)\n",
    "\n",
    "X_test=to_categorical(X_test,3)\n",
    "Y_test=to_categorical(Y_test,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare stateful batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_s=50\n",
    "#first create stateful mini-batches from the training data\n",
    "batches=np.int(len(X_train)/batch_s)\n",
    "idx=np.arange(0, batches*batch_s,batches)\n",
    "for i in range(1,batches):\n",
    "    idx=np.append(idx,np.arange(0, batches*batch_s,batches)+i)\n",
    "print(idx[0:100])\n",
    "X_train_stateful=np.zeros((len(X_train),lookback,3))\n",
    "for i in range(0,len(idx)):\n",
    "    X_train_stateful[i]=X_train[idx[i]]\n",
    "Y_train_stateful=np.zeros((len(Y_train),2))\n",
    "for i in range(0,len(idx)):\n",
    "    Y_train_stateful[i]=Y_train[idx[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create stateful mini-batches from the validation data\n",
    "batches=np.int(len(X_valid)/batch_s)\n",
    "idx=np.arange(0, batches*batch_s,batches)\n",
    "for i in range(1,batches):\n",
    "    idx=np.append(idx,np.arange(0, batches*batch_s,batches)+i)\n",
    "X_valid_stateful=np.zeros((len(X_valid),lookback,3))\n",
    "for i in range(0,len(idx)):\n",
    "    X_valid_stateful[i]=X_valid[idx[i]]\n",
    "Y_valid_stateful=np.zeros((len(Y_valid),2))\n",
    "for i in range(0,len(idx)):\n",
    "    Y_valid_stateful[i]=Y_valid[idx[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the stateful RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "name = 'RNN_stateful'\n",
    "\n",
    "model.add(SimpleRNN(4, batch_input_shape=(50,lookback, 3),stateful=True))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train_stateful[0:50],Y_train_stateful[0:50],batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(X_train_stateful[0:50],batch_size=50)[0:5])\n",
    "print(Y_train_stateful[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the stateful RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    history1 = model.fit(X_train_stateful, Y_train_stateful, \n",
    "                        epochs=1, \n",
    "                        batch_size=50, \n",
    "                        verbose=2, \n",
    "                        validation_data=(X_valid_stateful,Y_valid_stateful),\n",
    "                        shuffle=False) \n",
    "    model.reset_states()  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After the training is completed we extract the learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1=np.row_stack(model.get_weights()[0:2])\n",
    "b1=model.get_weights()[2]\n",
    "W2=model.get_weights()[3]\n",
    "b2=model.get_weights()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 # stacked matrices of hidden and input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the test data for a stateful RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the test data for a stateful RNN model\n",
    "batch_s=50\n",
    "batches=np.int(len(X_test)/batch_s)\n",
    "idx=np.arange(0, batches*batch_s,batches)\n",
    "for i in range(1,batches):\n",
    "    idx=np.append(idx,np.arange(0, batches*batch_s,batches)+i)\n",
    "\n",
    "X_test_stateful=np.zeros((len(X_test),lookback,3))\n",
    "for i in range(0,len(idx)):\n",
    "    X_test_stateful[i]=X_test[idx[i]]\n",
    "Y_test_stateful=np.zeros((len(Y_test),2))\n",
    "for i in range(0,len(idx)):\n",
    "    Y_test_stateful[i]=Y_test[idx[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the prediction on the first two examples of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the hidden state to zero\n",
    "model.reset_states()\n",
    "# predict the first two mini-batches (each has size 50)\n",
    "y_pred1=model.predict(X_test_stateful[0:100],batch_size=50)\n",
    "print(y_pred1.shape) # we get for each time point the 2dim prediction\n",
    "# check the prediction of the first instance in minibatch 1 and in minibatch 2 (each mini-batch has size 50):\n",
    "# below we will do this by hand and check if we get same predictions\n",
    "print(y_pred1[0])\n",
    "print(y_pred1[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One forwardpass of a stateful RNN in numpy by \"hand\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first determine the prediction of the first instance of mini-batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the ingoing hidden state for the first example of the test data:\n",
    "h0=np.array((0,0,0,0),dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1=np.tanh(np.matmul(np.concatenate((X_test_stateful[0][0],h0)),W1)+b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2=np.tanh(np.matmul(np.concatenate((X_test_stateful[0][1],h1)),W1)+b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=np.matmul(h2,W2)+b2\n",
    "np.exp(Z)/np.sum(np.exp(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same again but this time with a for loop to go over the elements of a sequence\n",
    "# initialize hidden state of first(!) mini-batch with zeros\n",
    "ht_m1=np.array((0,0,0,0),dtype=\"float32\") \n",
    "\n",
    "for i in range(0,lookback):\n",
    "    ht_m1=np.tanh(np.matmul(np.concatenate((X_test_stateful[0][i],ht_m1)),W1)+b1)\n",
    "Z=np.matmul(ht_m1,W2)+b2\n",
    "np.exp(Z)/np.sum(np.exp(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now determine the prediction of the first instance of mini-batch 2 (stateful connected to first instance of mini-batch 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to define the incoming hidden state for the second example of the test data\n",
    "\n",
    "ht_m2 = \n",
    "\n",
    "for i in range(0,lookback):\n",
    "    ht_m2=np.tanh(np.matmul(np.concatenate((X_test_stateful[50][i],ht_m2)),W1)+b1)\n",
    "Z=np.matmul(ht_m2,W2)+b2\n",
    "np.exp(Z)/np.sum(np.exp(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the Performance of the stateful RNN is better than the simple RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_states()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred=model.predict(X_test_stateful,batch_size=50,)\n",
    "print(confusion_matrix(np.argmax(Y_test_stateful,axis=1), np.argmax(pred,axis=1)))\n",
    "np.sum(np.argmax(pred,axis=1)==np.argmax(Y_test_stateful,axis=1))/len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
