{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise on Recurrent Neural Network\n",
    "\n",
    "In this exercise we want to use RNNs for predicting if a ice cream store has ice on stock.\n",
    "We only can use the past weather to make our predictions and hope that the ice stock depends on the weather in the past couple of days. \n",
    "To asses if our RNN model prediction is useful we want to compare the RNN prediction performance to an easy baseling prediction model. As baseline prediction model we use a random forest.\n",
    "\n",
    " \n",
    "The weather is described by 3 states: 0=sunny, 1=cloudy and 2=rainy. People only buy ice when its sunny and the ice cream \n",
    "stand has an unknow stock of ice and reorders sometimes (unknown policy but we hope it depends on the weather).  \n",
    "Unfortunately, we are quite busy with working so we can  only remember the weather of the last 2 days - for that reason our lookback is only 2 days.\n",
    "\n",
    "\n",
    "a) Go to the beginning of paragraph *Prepare data* and look at the real data generating process is in cell 2. Have a look at the code and try to understand the process (not necessary to continue).\n",
    "\n",
    "\n",
    "b) Go to the beginning of paragraph *Train and evaluate the baseline Random Forest model*. How large is the accuracy of the random forest model?\n",
    "\n",
    "\n",
    "c) Go to the beginning of paragraph *Train and evaluate the RNN model* and look RNN model definition. Draw the corresponding computational graph of the unrolled model.\n",
    "\n",
    "\n",
    "d) Here's is the model summary of the RNN, explain the Param # for the SimpleRNN layer and Dense layer.\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "simple_rnn_1 (SimpleRNN)     (None, 4)                 32        \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 2)                 10        \n",
    "_________________________________________________________________\n",
    "activation_1 (Activation)    (None, 2)                 0         \n",
    "=================================================================\n",
    "Total params: 42\n",
    "Trainable params: 42\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```\n",
    "\n",
    "\n",
    "d) What is the size of our hidden state in the model and where do we define it?\n",
    "\n",
    "\n",
    "e) Do you expect that the ice store has ice on stock on day 2 and day 4?\n",
    "Hint: Take the trained model and predict the first two examples of the test set\n",
    "\n",
    "\n",
    "f) To understand what excactly is done by the RNN model, check the prediction \n",
    "by \"hand\"/\"numpy\" with the learned weights from the model.  \n",
    "\n",
    "Hint: use model.get_weights() to get the leraned weights!\n",
    "\n",
    "f) Compare the performace of the Random Forrest and the RNN, how good are the models?  \n",
    "What could be the reason for the observed performaces?\n",
    "Hint: keep in mind the data generating process\n",
    "\n",
    "\n",
    "f) What do you expect, if you increase the lookback? Play around with this parameter and check if your expectation was right.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__, sys.version_info\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    Xs = np.array(np.random.choice(3, size=(size,))) #Random Weather\n",
    "    Y = []\n",
    "    ice = 2 # stock of icecream at start\n",
    "    for t,x in enumerate(Xs):\n",
    "        # (t-3) >= 0 the first ice cream could be delivered on day 3\n",
    "        # Xs[t - 3] cloudy three days before today => we ordered ice cream\n",
    "        # ice < 2 not full\n",
    "        if (t - 3) >= 0 and Xs[t - 3] == 1 and ice < 2: \n",
    "            ice += 1\n",
    "        if x == 0: # It is sunny we therefore sell ice, if we have\n",
    "            if ice > 0: # We have ice cream\n",
    "                ice -= 1\n",
    "        if ice > 0: #We are not out of stock\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "    return Xs, np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating the data and split it to a train valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = gen_data(40000) \n",
    "\n",
    "lookback=2  # how many days of weather info we use\n",
    "\n",
    "X_tr = X[0:20000]  # number of days with weather in train data\n",
    "Y_tr = Y[0:20000]\n",
    "idx=np.arange(0, len(X_tr),lookback)  \n",
    "X_train=np.zeros((len(idx),lookback))\n",
    "Y_train=np.zeros((len(idx),1))\n",
    "for i in range(0,len(idx)-1):\n",
    "    X_train[i]=X_tr[idx[i]:idx[i+1]]\n",
    "    Y_train[i]=Y_tr[idx[i]+lookback]\n",
    "\n",
    "X_va = X[20000:30000]\n",
    "Y_va = Y[20000:30000]\n",
    "idx=np.arange(0, len(X_va),lookback)\n",
    "X_valid=np.zeros((len(idx),lookback))\n",
    "Y_valid=np.zeros((len(idx),1))\n",
    "for i in range(0,len(idx)-1):\n",
    "    X_valid[i]=X_va[idx[i]:idx[i+1]]\n",
    "    Y_valid[i]=Y_va[idx[i]+lookback]\n",
    "\n",
    "X_te = X[30000:40000]\n",
    "Y_te = Y[30000:40000]\n",
    "idx=np.arange(0, len(X_te),lookback)\n",
    "X_test=np.zeros((len(idx),lookback))\n",
    "Y_test=np.zeros((len(idx),1))\n",
    "for i in range(0,len(idx)-1):\n",
    "    X_test[i]=X_te[idx[i]:idx[i+1]]\n",
    "    Y_test[i]=Y_te[idx[i]+lookback]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare the data for the Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_RF=pd.DataFrame(X_train)\n",
    "for i in range(0,lookback):\n",
    "    X_train_RF[i]=X_train_RF[i].astype('category')\n",
    "#X_train_RF.dtypes\n",
    "\n",
    "Y_train_RF=pd.DataFrame(Y_train)\n",
    "Y_train_RF[0]=Y_train_RF[0].astype('category')\n",
    "#Y_train_RF.dtypes\n",
    "\n",
    "X_test_RF=pd.DataFrame(X_test)\n",
    "for i in range(0,lookback):\n",
    "    X_test_RF[i]=X_test_RF[i].astype('category')\n",
    "#X_train_RF.dtypes\n",
    "\n",
    "Y_test_RF=pd.DataFrame(Y_test)\n",
    "Y_test_RF[0]=Y_test_RF[0].astype('category')\n",
    "#Y_train_RF.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting to one hot encoding for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "X_train=to_categorical(X_train,3)\n",
    "Y_train=to_categorical(Y_train,2)\n",
    "\n",
    "X_valid=to_categorical(X_valid,3)\n",
    "Y_valid=to_categorical(Y_valid,2)\n",
    "\n",
    "X_test=to_categorical(X_test,3)\n",
    "Y_test=to_categorical(Y_test,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the baseline Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=22)\n",
    "clf.fit(X_train_RF,np.ravel(Y_train_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred=clf.predict(X_test_RF)\n",
    "print(confusion_matrix(Y_test_RF, pred))\n",
    "\n",
    "# your code here to determine the accuracy:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense, SimpleRNN, TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define and train RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "name = 'RNN'\n",
    "\n",
    "model.add(SimpleRNN(4, batch_input_shape=(None,lookback, 3)))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(X_train[0:5]))\n",
    "print(Y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "                    batch_size=32,\n",
    "                    epochs=20, \n",
    "                    verbose=2,\n",
    "                    validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to extract the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets prepare the matrices and biases to do the prediction by hand:\n",
    "W1=np.row_stack(model.get_weights()[0:2])\n",
    "b1=model.get_weights()[2]\n",
    "W2=model.get_weights()[3]\n",
    "b2=model.get_weights()[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the trained model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to make a prediction of the first observation in the test set:\n",
    "y_pred1=\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forwardpass in numpy by \"hand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0=np.array((0,0,0,0),dtype=\"float32\")\n",
    "# intialize hidden state with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to determine the activation of the hidden state of the first of the two days\n",
    "# hint: use W1 and b1\n",
    "h1="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to determine the activation of the hidden state of the second of the two days\n",
    "# hint: use W1 and b1\n",
    "h2="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to determine the predicted probabilities for ice (yes or no)\n",
    "# hint: use W2 and b2\n",
    "Z=\n",
    "np.exp(Z)/np.sum(np.exp(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same in a loop:\n",
    "ht=np.array((0,0,0,0),dtype=\"float32\")#first hidden stare = all zeros\n",
    "for i in range(0,lookback):\n",
    "    ht=np.tanh(np.matmul(np.concatenate((X_test[0][i],ht)),W1)+b1)\n",
    "Z=np.matmul(ht,W2)+b2\n",
    "np.exp(Z)/np.sum(np.exp(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)\n",
    "print(confusion_matrix(np.argmax(Y_test,axis=1), np.argmax(pred,axis=1)))\n",
    "np.sum(np.argmax(pred,axis=1)==np.argmax(Y_test,axis=1))/len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
