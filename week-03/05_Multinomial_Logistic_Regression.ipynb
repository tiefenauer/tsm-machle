{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression\n",
    "\n",
    "In this script we use multinomial logistic regression to predict the handwritten digits of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)\n",
      "1.2.1\n",
      "(4000, 1, 28, 28) (4000,) 28\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bfa6e36128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import numpy as np\n",
    "\n",
    "# To be compatible with python3\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "\n",
    "import gzip\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "print(sys.version_info)\n",
    "print(tf.__version__)\n",
    "\n",
    "with gzip.open('./mnist_4000.pkl.gz', 'rb') as f:\n",
    "    (X,y) = pickle.load(f, encoding='latin1')\n",
    "PIXELS = len(X[0,0,0,:])\n",
    "print(X.shape, y.shape, PIXELS) #As read\n",
    "fig = plt.figure(figsize=(10,30))\n",
    "for i in range(3):\n",
    "    a=fig.add_subplot(1,3,(i+1))\n",
    "    plt.imshow(-X[i,0,:,:], interpolation='none',cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to reshape for the logistic regression\n",
    "X = X.reshape([4000, 784])\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label\n",
      "[5 0 4 1 9]\n",
      "class label in OneHot encodig\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Taken from http://stackoverflow.com/questions/29831489/numpy-1-hot-array\n",
    "def convertToOneHot(vector, num_classes=None):\n",
    "    result = np.zeros((len(vector), num_classes), dtype='float32')\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result\n",
    "print(\"class label\")\n",
    "print(y[0:5])\n",
    "print(\"class label in OneHot encodig\")\n",
    "print(convertToOneHot(y[0:5], 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "#Note that we usually do not like to specify the batchsize. Choosing it `None` will leave it open\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='x_data')\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_data')\n",
    "\n",
    "# We start with random weights a\n",
    "w = tf.Variable(tf.random_normal([784, 10], stddev=0.01))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#<-------------------------- Your code here ---------------\n",
    "# Your code here, do a matrix multiplication between x,w and an addtion of b\n",
    "z = tf.matmul(x, w)+ b\n",
    "# End of your code\n",
    "\n",
    "prob = tf.nn.softmax(z)\n",
    "init_op = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the graph and visualize it in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.FileWriter(\"/tmp/dumm/mlp_tensorflow_solution/\", tf.get_default_graph()).close() #<--- Where to store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing a forward pass of the untrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true label =  5\n",
      "\n",
      "probability for each class =  [0.11525529 0.13671385 0.08958027 0.07389172 0.11342652 0.10523579\n",
      " 0.10331967 0.07971239 0.07903792 0.1038266 ]\n",
      "\n",
      "pred label =  1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    res_val = sess.run(prob, feed_dict={x:X[0:10]})\n",
    "print(\"true label = \",y[0])\n",
    "print()\n",
    "print(\"probability for each class = \",res_val[0])\n",
    "print()\n",
    "print(\"pred label = \",np.argmax(res_val[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3054888\n",
      "0.17248896\n",
      "0.24261814\n",
      "0.10119972\n",
      "0.09055482\n",
      "0.055978358\n",
      "0.043627013\n",
      "0.03691905\n",
      "0.022943757\n",
      "0.01862003\n",
      "Loss for the validation set\n",
      "0.5240501\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(prob), reduction_indices=[1]))\n",
    "\n",
    "#train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "train_op = tf.train.AdagradOptimizer(0.1).minimize(loss)\n",
    "init_op = tf.global_variables_initializer() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for i in range(1000):\n",
    "        idx = np.random.permutation(2400)[0:128] #Easy minibatch of size 128\n",
    "        #res, out_val, _ = sess.run((loss, prob, train_op),feed_dict={x:X[idx], y_true:convertToOneHot(y[idx], 10)})\n",
    "        loss_, out_val, _ = sess.run((loss, prob, train_op),feed_dict={x:X[idx], y_true:convertToOneHot(y[idx], 10)})\n",
    "        if (i % 100 == 0):\n",
    "            print(loss_)\n",
    "    \n",
    "    # Get the loss for the validation results (from 2400:3000)\n",
    "    print('Loss for the validation set')\n",
    "    #<-------------------------- Your code here ---------------\n",
    "    loss_val = sess.run((loss), feed_dict={x: X[2400:3000], y_true: convertToOneHot(y[2400:3000], 10)})#get loss here\n",
    "    print(loss_val)\n",
    "    # Get the results for the validation set\n",
    "    res_val = sess.run((prob), feed_dict={x: X[2400:3000]})#get probs here\n",
    "    #<-------------------------  End of your code here --------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.88\n",
      "probs = [0.   0.01 0.   0.   0.   0.   0.   0.   0.99 0.  ]\n",
      "predicted label = 8\n",
      "true label = 8\n"
     ]
    }
   ],
   "source": [
    "# and estimate the preformance on the validation set\n",
    "# Your code here\n",
    "print(\"Accuracy =\",np.mean(np.argmax(res_val, axis = 1) == y[2400:3000]))\n",
    "import random \n",
    "rmd=random.randint(2400,3000)\n",
    "print(\"probs =\",np.round(res_val[rmd-2400],2))\n",
    "print(\"predicted label =\",np.argmax(res_val[rmd-2400]))\n",
    "print(\"true label =\",np.round(y[rmd],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
